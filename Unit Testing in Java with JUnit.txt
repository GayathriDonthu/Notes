										Unit Testing in Java with JUnit
										===============================
										
JUnit Overview
==============

JUnit - testing framework

assertion - comparing the actual with the expected result

-> write test cases in a separate class file, mark each test case with @Test annotation. The JUnit runner executes those test cases. 

JUnit features
--------------

1. Asserts 
2. Test setup and tear down -> setup test data before our test actually runs and teardown that data or context after it runs.
							-> ensures that test code is not repetetive.
3. Exception testing -> checks for exception not thrown and thrown
4. Test suites -> useful for managing large amount of tests.
5. Parameterized testing -> we can create tests that operate on sets of data that we feed into those tests. 
6. Assumptions -> to ignore tests that aren;t even qualified to run on a platform or context. 
7. Rules -> allows to extend the functionality of JUnit by adding behaviours to tests that happen whenever we use a particular rule.
8. Theories -> special kind of tests that work under different contexts.
			-> We can set them up with different data and make sure those theories still hold.
9. Integration with popular build systems.

JUnit(image from desktop)
-----

Test code -> Tests an SUT(Subject under Test)

SUT -> is a Java class, doesnt have to be since JUnit can be more than unti testing. 

-> The test code we write uses the capabilities of the JUnit framework to make it easier to compare results and do other things.
-> Includes annotations that tells JUnit to recognize it as a Test.

JUnit runner -> to run the test, it looks the test code and determines what tests exist and how it should run them and report those results. It also has the ability to report the results to a view.

-> We can setup JUnit to run and output results files, which can be picked up by our build system or another tool.

Unit testing
------------

Unit -> class -> smallest unit
more than class -> integration tests etc
calling database -> not a unit test

Kent Back -> founder of Agile
Kent Back and Erich Gamma -> creators of JUnit

JUnit basics
============

JUnit test method
-----------------

-> To create unit tests in JUnit, we need to create test methods.
@Test
public void testMethod(){
}

JUnit Annotations
-----------------

1. @Test
2. @Before 
3. @After 
	-> Before and After annotations work together to allow us to specify some behaviour to happen before and after each test is run. 
4. @BeforeClass
5. @AfterClass
	-> allows us to specify some behaviour that happens before any methods in a test class are executed and after all the methods are executed.
6. @Ignore
	-> tells JUnit runner to ignore this test, useful for temporarily disabling a test.
7. @Test(Expected = Exception.class)
	-> allows us to expect that an exception will be thrown in our testMethod
8. @Test(timeout = 100)
	-> allows us to specify a period that the test should execute in, otherwise it will time out.
	
	
Before and After
----------------

-> @Before and @After annotations eliminate duplication in unit tests. 
-> public void Method annotated with @Before will be called before each test class is run like a setUp.
-> This is useful in setting up some data that all tests will use and resetting that data before running each new test. 
-> Tests dhouldn't be run in a particular order.
-> @After annotation works exactly like @Before except that it runs after each test, like clean up code.

BeforeClass and AfterClass
--------------------------

-> @BeforeClass and @AfterCLass annotations can be used when we want to execute a method before any test methods in a class are executed or after all test methods in a class are executed. 
-> they are executed only 1 time each regardless of test case numbers.
-> they must be static methods.
-> useful when we want to setup test data once for all tests in a class and need to cleanup the data afterwards. 
-> useful for non unit testing uses of JUnit, like cleaning data in database after all tests are run.

Using Ignore
------------

-> @Ignore - test case will not be run. 
-> when the build is failing and we want to get a test that's failing out of there so that the build can continue, but we don't want to remove that test. We can use @Ignore.

Exception testing
-----------------

-> JUnit has built in support for helping us to write tests that check to make sure an exception was thrown and that it was a right kind of exception by using the test annotations expected field.
-> When we declare a test annotation, if we set the expected field = exception class, the test will only pass if an exception of that type is thrown.


Timing Out
----------
@Test(timeout = 100)
-> Make sure Method does right thing within a certain time limit. 
-> By setting timeout field on the @Test annotation in JUnit, we can specify a number of milliseconds in which time the test should complete. Otherwise, it will be considered as failure.
-> used in non unit test situations where network connection is there, and shouldn't hang up whole suite of tests we are executing.
-> 	used where a test case more time to execute.
Ex: 	@Test(timeout = 200)
	public void badTest(){
		for(int i=0; i< 10000000; i++)
			service.addProtein(1);
	}
	
	
Assertions
----------

1. assetArrayEquals
2. assertEquals - checks two objects are equal usign the equal operator.
3. assertTrue - checks boolean value
4. assertFalse - checks boolean value
5. assertNull - checks for null
6. assertNotNull - checks for not null
7. assertSame - checks the actual objects are the actual same excat objects 
8. assertNotSame - - checks the actual objects are not the actual same excat objects 
9. fail - want to fail the test, cases where we don't have an assert that really expresses what we want to check.


Advanced JUnit
==============

Test Suites
-----------

-> If we want to run multiple test classes together wihtout having to individually select and run each one, then we can use test suits.
-> Test suite class is annotated with the RunWith annotation and then tell it use the Suite.class.
-> This tells the JUnit to run this particualr test suite using the suite runner, which is capable of reading the Suite.SuiteClasses annotation and running any test classes contained within it.

@RunWith(Suite.class)
@Suite.SuiteClasses(...) 
						 __________________ Test class	
						 |	
Test Suite---------------------------------> Test class
						 |__________________ Test class
						 

@RunWith(Suite.class) -> Tells Test Suite class what to run i.e., Suite.class
@Suite.SuiteClasses(...)  -> tells us what classes that this particular suite is made up of.

we can add multiple classes for multiple tests.

@Suite.SuiteClasses({	HelloJUnitTest.class,	TrackingServiceTests.class}) 

-> Eclipse IDE will use the Suite class runner, which is built into the IDE, when we run it all the tests classes are run. 

Categories
---------


@RunWith(Categories.class)
@IncludeCategory(A.class)
														 @Category(A.class)
								|----------------------> Test Class
								|						 
								|						 @Category(A.class)	
Test Suite --------------------------------------------> Test class
								|
								|						 @Category(A.class)
								|----------------------> Test Method

-> similar to test suites in JUnit. 
-> Category runner is aspecial kind of suite runner that is able to read category annotations off of test methods or test classes and determine whether or not to run the containing test depending on whether or not the categories matched the categories specified in the include category annotation on the test suite. 
-> In JUnit we can add a category to any test method by using the category annotation and then specifying the class of the category.
-> A catrgory class is juts a blank interface only used as a marker, but it can also be a class. 
-> Inheritance applies to categories, can create category hierarchy.

@RunWith(Categories.class)
@IncludeCategory(GoodTestsCategory.class)
@ExcludeCategory(BadTestsCategory.class)
@Suite.SuiteClasses({
	HelloJUnitTest.class, 
	TrackingServiceTests.class
})
public class GoodTestsSuite {

}

-> It filters based on what;s included, here we included GoodTestsCategory. So, it runs the tests that belong to this category and eclused the BadTestsCategory.


Parameterized Tests
-------------------

-> developers problem - repetetive test only vary in the input and expected output.This is resolved by parameterized tests. 
-> We can use parameterized tests to pass a set of inputs and expected outputs into a test class and have our tests run against those nputs and check against the expected results without having to create a test case for each pair. 

@Parameters
static method{
	return collection of arrays 1 item for input and 1 item for expected result.
}

-> create a test class that has a constructor that takes an input and an expected result and sets those values to the fields in the class. 
-> We create our test that reply on the input and expected results values stored in the fields in our class. 


Advanced Assertions
--------------------


AssertThat([value], [matcher statement])
							|
							|
							|
							-------------> Is, HasItem, Contains String, IsNull, AllOf
							
AssertThat annotation -> uses Hamcrest library to give us the ability to use powerful matchers to construct elegant assertions in our tests. 

-> With the AssertThat format, we first specify the value we want to check. Thsi would be the actual value in our normal JUnit test, then we specofy a matcher statement. 
-> A matcher statement is like all the items in our collection contain a string with the test high in them. 
-> We can write the matcher statements by combining different matchers together. 

Instead of assert = 3, AssertThat results is 3.

Ex: 

assertEquals(10, service.getTotal());
assertThat(service.getTotal(), is(10));

Advanced Exception Testing
--------------------------

						@Rule
						ExpectedException
						     |
							 |
							 |
							 |
						@Test
						Test Method
						
-> We can use the expected exception rule to create a special set of assertions in our tests, which will check that a particular exception is thrown and/or that a specific message is set on the exception. 
-> To use the expected exception rule, create public field of type expected exception that's annotated witht he rule annotation and then in our test method we call the expect method on the expected exception field to set up an expectation that a particular exception should be thrown or we can call the expect message method to ensure that a particualr message exists on that exception.
-> We can test the message of the exception. 


Rules
-----

-> JUnit provides more rules and allows us to create own rules that can be used to extend JUnit itself.
-> Rules are the way to hook into JUnit to add some functionality before or after a test is run. 
-> Ex: rules allow to specify a before and after annotation pair that goes together whenever we use the rule.
-> We can call methods on rules and they can hold data, but basic idea is to add some functionality to a test with a simple declaration. 

1. TemporaryFolder
2. ExtrenalResource
3. ErrorCollector -> used to collect multiple errors and display them at once instead of immediately failing a test.
4. Verifier
5. TestWatcher
6. TestName
7. Timeout -> allows to specify a timeout for an entire set of tests in a test class. 
8. ExpectedException
9. RuleChain -> lets us chain multiple rules together.
10. @ClassRule -> works at the class level.

To know more about rules -> junit page 

Theories
--------


@DataPoint
Static method {
	@Theory
	Test method

}

-> similar to parameterized test. 
-> Theory is a test that holds true under all conditions that meet a set of assumptions. 
-> We can create a theory by using the theory annotation instead of the test annotation on a test method.
-> Theory method will use a single parameter of any data type we like and will use that as input for the test.
-> difference between a theory and parameterized test is that the theory will have the same expected result for all inputs. 
-> We setup the test data by using the data point annotation that either returns a single piece of data to test or a collection of inpits. 

Ex: 

If we add a positive value to addProtein, the total will always be a positive value.

@DataPoint -> will be one data point, specify one at a time
@DataPoints -> we can specify a bunch of them at once. 

Integrating JUnit
================

-> The JUnit runner, built into Eclipse is handy for running tests quickly while we're doing development, not an option for automating the running of JUnit tests. 

Alternative runners for auomtation

1. Use a runner class that is built into the framework and run the JUnit tests using this runner directly from some Java code. 	
   Using this option we can create a Java application and in that application, call the runner to run the tests. 
   This allows us to have a standard applicationcapable of running our JUnit tests.
   
2. Invoke the JUnit runner directly from the command line. We can do this by just invoking the JUnit runner using the Java   
   command and specifying the test classes we want to run. 
   
Console Runner
--------------
  
1st method:


public class ConsoleRunner {

	public static void main(String[] args) {
		
		JUnitCore junit = new JUnitCore();
		
		junit.addListener(new TextListener(System.out));
		
		junit.run(TrackingServiceTests.class);
		
		
	}

}


JUnitCore junit = new JUnitCore(); 

-> it gives runner that we can run tests with.

junit.addListener(new TextListener(System.out)); 

-> If we just run the tests using the runner(junit), by default it's not going to output anything, but by adding the listener, it's going to put out the output to System.out.

junit.run(TrackingServiceTests.class); -> Test class that we want to run.

-> When we run the above class as Java Application, it gives output. We get Before After stuff that we put in the TrackingServiceTests file, we can also see the failure, where the failure was, why it failed, and summary giving no. of test failed. 

-> This is easier way to get results from our runs.We can use this if we don't want to use the built in runner.


Getting JUnit jars
------------------

-> We don't need above code to run JUnit just using java from command line, but we need the JUnit JARs. 
-> For command line version of running JUnit, 

download the jars from junit.org -> clikc on download and install -> we need 2 jars

junit.jar
hamcrest-core.jar

Running from the command line
-----------------------------

2nd method:

Specify classpath in command line

junit libraries path followed by our jar file


-> We need to execute the runner, so we need to fully specify the name of this runner, which will be org.junit.runner.JUnitcore then we need to specify the tests that we want to run(fully qualified name) com.proteinTracker.tests.TrackingServiceTests

java -cp C:\Users\gayathri.guttikonda\Desktop\Gayathri\Libraries\junit\*;C:\Users\gayathri.guttikonda\Desktop\Gayathri\jars\ProteinTracker.jar org.junit.runner.JUnitCore com.proteinTracker.tests.TrackingServiceTests

Run this in command line, we get similar output as in Console runner.

Before 
After
---

Tests run : 5, Failures: 4

JUnit and Ant
-------------

-> JUnit and Ant work together nicely. Ant provides some tasks that we can use to run JUnit tests in an Ant build scipr with minimal effort.
-> When integrating JUnit into Ant scripts, all the options available for setting up a JUnit task can be a bit overwhelming.
-> Basic idea is to make it so the JUnit target in Ant depends on both the source code being compiled and the test code being compiled.

Creating an Ant build file
--------------------------

ProteinTrackerTest -> Right click -> Export -> ant build files -> select ProteinTracker and ProteinTrackerTests projects 

We can see the build.xml files in both the projects.

Running with Ant
----------------

1. Right click on build.xml -> run as Ant build

2. Right click on build.xml -> run as External Tools Configuration -> Targets -> select the specified test we want to run

JUnit Reporting 
-------------------

build.xml -> Run as -> External Tools configuration -> New configuration(icon) -> Name it as JUnit report -> targets -> specify only junitreport -> Run 

We get xsl sheet and the build will be successful.

JUnit and Maven
---------------

-> JUnit also integrates nicely with Maven.

Convert both ProteinTracker and ProteinTrackerTests projects to Maven project 

Project -> Right click -> COnfigure -> COnvert to maven project

In the pom.xml of ProteinTrackerTests, add the 2 dependencies

1. ProteinTracker project dependency.
2. junit dependency

Now, Run mvn clean install on ProteinTracker

Run ProteinTrackerTests -> Right click -> Run As -> mvn install

BY default JUnit in Maven looks for classes that end with Test, Ex: HelloJUnitTest.java

mvn test -> only HelloJUnitTest.java is picked up and it ran only that.


Code Coverage
-------------

-> Code coverage referes to the measure of how much of your source code is executed by our unit tests or other tests.
-> Most code coverage tools work by first instrumenting our code with some code that will keep track of what lines of code were executed and what caused them to be executed. 
-> The tool will run our test against the instrumented code to produce a report of what code was actually executed.
-> The raw report data is transformed into some readable format that gives you the percentages of code executed and other useful information.

Code coverage tools with JUnit

1. EclEmma -> plugin for Eclipse, allows us to generate code coverage information directly in Eclipse when we are running our 	
			  tests. 
		   -> useful in getting immediate feedback on how effective tests are.
		   
2. Cobertura -> It's a mature code coverage tool for JUnit that we can use to automate code coverage reports so that we can have 
			    our build system generate the code coverage reports when it runs our tests. 
				
				
Using EclEmma
-------------

Install EclEmma from Eclipse market place.

click on ProteinTrackerTests project, Rrun(red and green icon) -> Converage As -> JUnit

We get the coverage results in the JUnit view

ProteinTrackerTests -> 86.6 %

ProteinTracker -> 75%

open TrackingService.java file -> It has some green lines and yellow lines

green lines -> lines executed
yellow lines -> missed a particular branch
red lines -> lines not executed at all


Cobertura
---------

cobertura.sourceforge.net -> download cobertura.jar file

Beyond JUnit
============

COntinous Testing
-----------------

			Modifying tests -------------------------> running tests
							<------------------------
							

-> When developing, we may be modifying sourc and running tests continously, this can be automated by tools and this is called continous testing.
-> A continous testing tool will monitor our source code and when it detects a change, automatically runs JUnit tests that are associated with that code. 
-> Infinitest is a continous Testing tool that plugs right into eclipse.

junit.org -> wiki -> JUnit Usage and Idioms - Continous Testing -> IDE plugins http://infinitest.github.com/ 

 drag & drop the icon install to a running Eclipse.
 
 Eclipse Marketplace is opened -> install Infinitest
 
 We get Infinitest is waiting for changes.
 
 
ProteinTracker -> make any change in source code Ex: TrackingService.java file, we can see that the test suites running automatically and we get message saying 6 test cases ran at timestamp.

We cna check the console for the test results.

Problems view -> it shows the tests failed, if we click on them it goes to the line where error occured.

-> We can correct those errors and the problems disappear.

Dependencies
------------

Dealing with dependencies while doing unit testing can be done in 2 ways

1. Stubs
2. Mocks

Stubs(image from desktop)
-----

-> Easiest way to deal with dependencies when unit testing is to use a stub.
-> A stub is basically some code that pretends to be the dependency, SUT - subject under test, is using.
-> It allows us to test SUT code without having to test any other dependencies the code uses.
-> In java, we usually create a stub first by creating an interface that represents our dependency and then creating a stub class that implements that interface.
-> The stub class doesn't do anything but return back dummy data and perhaps store a little bit of information about its state.

Adding a dependency
-------------------

-> In our example, the dependency item is HistoryItem.java, which is simple DTO no need of creating any kind of stub for this, we can use it as is becoz it just holds data.

So add a dependency in Tracking service

private Notifier notifier;

if(total > goal)
{
	boolean sendResult = notifier.send("goal met");
	String historyMessage = "sent:goal met";
	if(!sendResult)
		historyMessage = "send_error : goal met";
	history.add(new HistoryItem(historyId++, 0, historyMessage, total));
}
 
 
package com.protein;

public interface Notifier {

	boolean send(String message);

}


Creating a Stub
---------------

Notifier message may be written by another team, but in order to use it in our testing, we create a NotifierStub by implementing the interface Notifier.

public class NotifierStub implements Notifier {

	@Override
	public boolean send(String message) {
		return true;
	}

}

-> We can use this stub in our trackign service in order to just pretend like it is hooked up to the real notifier. 
-> This will allow us to test our code in isolation. 


Create a TrackingService constructor and pass Notifier as an argument.

public TrackingService(Notifier notifier) {
	this.notifier = notifier;
}

-> We can see that tests are failing since new TrackingService(); is present, so replace it with new TrackingService(new NotifierStub());

Testing with a Stub
-------------------

-> create a tests case that will demonstrate that the code that is using our stub is working.
-> We are testing that our history in our class is updated, we're not testing that we actually set the notification becoz we don't have a way to do that with a stub. We can do that using mock.
-> Now, we are just checing the functionality that history should be updated.

@Test
public void whenGoalIsMetHistoryIsUpdated() throws InvalidGoalException{
	service.setGoal(5);
	service.addProtein(6);
	
	HistoryItem result = service.getHistory().get(1);
	assertEquals("sent:goal met", result.getOperation());
}

Mocks(image from desktop)
-----
 
-> Problem with stubs - stubs don't actually test anything.
-> A stub just allows the SUT to call methods on it and returns dummy data to the SUT.
-> Need to verify that a SUT is making correct calls out to its dependencies and that it's only makign those calls and no additional calls. 
-> We can test this behaviour and still isolate our SUT by using a mock instead of a stub.
-> A mock object will act like the real dependency, but it will also record what calls were made to it.
-> A mock can also be setu to return specific data under certain conditions.
-> In our test code after we run our tests, we can check with the mock to verify that what we expected to happen actually happened as a condition of our test.

JMock
-----

-> JMock is the commonly used mocking framework.

jmock.org -> download jar and set up inside the project.

Using JMock
-----------

-> Add below jars into buildpath of the ProteinTrackerTests

hamcrest-core.jar
hamcrest-lirary.jar
jmock-2.6.0.jar

-> Make sure that the junit is below the hamcrest jars, so that hamcrest are used before junit. Becoz JUnit uses different version of hamcrest jars, it can have problems when we try to do the mock since it is using a later version. 

Mockery context = new Mockery();
final Notifier mockNotifier = context.mock(Notifier.class);

-> In JMock, we create Mockery to test.
-> The above code will give us an object that implements Notifier interface that we can control how it responds to calls on it, just like a stub, and we can get information about what has happened to it.

-> We setup some expectations and then we check those expectations.

service = new TrackingService(mockNotifier);

-> Passing mockNotifier instead of the stub.

-> setup a check. There's a language that we can use basically out of these hamcrest matchers.

context.checking(new Expectations() {{
	oneOf(mockNotifier).send("goal met");
	will(returnValue(true));
}});

-> Here, we expect that this Send should be called on mockNotifier with goal met one time. 
-> If it doesn't happen, when we check our context later when we verify that everything happenend, it's going to fail.
-> If it happens more than once, it'wll also fail. It's needs to happen exactly one time. 
-> We can also make it so that this will return a value.

context.assertIsSatisfied(); -> This makes sure that whatever we specified here has actually happened. If we don't put this in, it won't check any of this. So we do have to put this in. Thsi is our assert.

Now the test case passes.

-> If we change the string to 1goal met, We get an error, ExpectationErorr unexpected invocation. We were expecting the wrong string that was being passed in here. If this isn't called or the wrong thing is called, it's going to fail that test and that's the value of using a mock is that the mock is able to check that certain things were called on it.
-> By using JMock, we can set this up. no need of writing code as we did for NotifierStub. Instead we dynamically creating a mock, we're setting up some expectations on that mock, and then we're asserting those expectations happened. 

Integration testing
-------------------

-> JUnit can also be used to do integration level testing.
-> When we do integration testing, we don't care about isolating the SUT from its dependencies. We wnat to make sure the SUT is using its dependencies becoz we want to test that everything works together. 
-> We can use JUnit to create integration tests, but be careful as we use real databases, this is where before and After help us manage resources.

The SMS Notifier(image from desktop)
----------------

-> We'll be creating an integration test for our tracking service by creating a real implementation for the notifier interface. 
-> This implementation will create a send notification through SMS when goal is reached.
-> We use Java Library that lets us check and send SMS messages through Google Voice.
-> Our test code will call the tracking service, which will send the SMS message through the SMS notifier. Then our tests code will call Google Voide itself to verify the message was sent.
-> Have test code cleanup the messages so that the tests can be run again and we don't leave anything behind.

Integration Test Overview
-------------------------

https://code.google.com/archive/p/google-voice-java/

download jar file

-> This library allows us to do Google voice. We are usign it to send a message.
-> It will basically fulfill that Notifier dependency in our class and it will really send a real message through Google voice. And this is one of the things that we perhaps want to do in an integration test is to test that it actually really works with the real system.
-> Need to create a demo Google voice account.

-> notifier.send is called, it dowsn't care whether this is a mock, a stub or the real implementation that sends via SMS. 

Selenium
--------

-> We can also JUnit to drive other testing frameworks such as Selenium to enable us to do even higher level automated testing. 
-> JUnit is very useful way to create Selenium tests that can automate a web browser to create tests that operate at the same level as a real user, it gives easy way to execute and organize tests, aeert conditions and see the results.
-> Selenium is an open source tool for automating web browsers.

Website:

http://docs.seleniumhq.org

Using Selenium
--------------

docs.seleniumhq.org -> downloads -> slenium server jar -> download the latest version

Download geckodriver.exe





		






